{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Notebook 2: Introduction to Deep Learning and PyTorch </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Why deep learning? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear perceptron model described in yesterdays introduction to machine learning can learn a linear boundary for binary classification tasks. This is a powerful technique, and one that works well when the underlying optimal decision boundary is itself linear. However, many practical problems involve the need for decision boundaries that are nonlinear in nature, and our linear perceptron model isnâ€™t expressive enough to capture this relationship.\n",
    "\n",
    "Consider the following set of data:\n",
    "\n",
    "<img src=\"../images/nonseparablelinear.png\" />\n",
    "\n",
    "We would like to separate the two colors, and clearly there is no way this can be done in a single dimension (a single dimensional decision boundary would be a point, separating the axis into two regions).\n",
    "To fix this problem, we can add additional (potentially nonlinear) features to construct a decision boundary from. Consider the same dataset with the addition of x^2 as a feature:\n",
    "\n",
    "<img src=\"../images/separablequadratic.png\" />\n",
    "\n",
    "With this additional piece of information, we are now able to construct a linear separator in the two dimensional space containing the points. In this case, we were able to fix the problem by mapping our data to a higher dimensional space by manually adding useful features to data points. However, in many high-dimensional problems, such as image classification, manually selecting features that are useful is a tedious problem. This requires domain-specific effort and expertise, and works against the goal of generalization across tasks. A natural desire is to learn these featurization or transformation functions as well, perhaps using a nonlinear function class that is capable of representing a wider variety of functions.\n",
    "\n",
    "(the part above taken from this note: https://inst.eecs.berkeley.edu/~cs188/fa23/assets/notes/cs188-fa23-note24.pdf)\n",
    "\n",
    "Now we will learn how to build a simple fully connected neural network, also known as a multi-layer perceptron. This model is used as a component in a vast variety of machine learning models. Some examples are the Transformer model, as well as image generation models (such as Dall-E). That means it is used to create stuff like this:\n",
    "\n",
    "<img src=\"../images/banana.png\" width=700 />\n",
    "\n",
    "and this:\n",
    "\n",
    "<img src=\"../images/gpt.jpg\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Fully Connected Neural Network </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first explore the data we are working with. This is a dataset gathered from Kaggle that contains API call sequences that can potentially be used to classify patterns of online activity as normal or malware. For more information, see https://www.kaggle.com/datasets/ang3loliveira/malware-analysis-datasets-api-call-sequences. \n",
    "\n",
    "<br/>\n",
    "\n",
    "We can use pandas to load the dataset and visualize it. It is now up to you how you wish to explore it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_data_path = Path.cwd().parent / \"data\" / \"malware_detection\" / \"dynamic_api_call_sequence_per_malware_100_0_306.csv\"\n",
    "malware_df = pd.read_csv(malware_data_path).set_index(\"hash\")\n",
    "malware_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore away!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had a lot of time and energy, and liked suboptimal solutions, we could spend a lot of time analysing the data to look for features that can be used for a classic machine learning model. Instead, let us build a neural network that learns the features for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Preparing the data for our neural network: the Pytorch Dataset class </h4>\n",
    "\n",
    "It is time to get the data on a format that our network can work with. We will use the PyTorch Dataset class, and define our own transformations to preprocess the input. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    This class inherits from the Pytorch Dataset class, so that it can be used with other convenient Pytorch \n",
    "    tools that we will shortly look at. This means that we need to define the \n",
    "    3 methods __init__, __len__, and __getitem___ that you can see below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            malware_df: pd.DataFrame,\n",
    "            preprocess=True,\n",
    "            to_torch=True\n",
    "            ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize all the variables you need to return samples from the dataset.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.malware_df = malware_df\n",
    "        self.preprocess = preprocess\n",
    "        self.to_torch = to_torch\n",
    "\n",
    "        if self.preprocess:\n",
    "            self.malware_df = MalwareDataset.preprocess_df(self.malware_df)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the size of the dataset, that means the total number of samples.\n",
    "        \"\"\"\n",
    "\n",
    "         ### Your code here\n",
    "\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index) -> dict:\n",
    "        \"\"\"\n",
    "        Return the sample at the specified index. Pytorch expects the output to be a dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        ### Your code here\n",
    "\n",
    "\n",
    "        # Remember to convert both the sequence vector and label to tensors if self.to_torch==True\n",
    "        call_seq_tensor = None\n",
    "        label = None\n",
    "\n",
    "        sample = {\n",
    "            \"call_seq\": call_seq_tensor,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "        return sample\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_df(df):\n",
    "        \"\"\"\n",
    "        Return the preprocessed dataframe. You can preprocess it any way you want,\n",
    "        but we recommend you look into normalizing and mean-centering (aka standardizing) the data\n",
    "        (https://www.geeksforgeeks.org/how-to-standardize-data-in-a-pandas-dataframe/).\n",
    "        \"\"\"\n",
    "\n",
    "         ### Your code here\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Preparing the data for batched processing: the Pytorch Dataloader class </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the primary advantages of using a library like Pytorch is the built-in support for parallelizability. Training deep  models is considerably sped up by processing many examples simultaneously, usually on a GPU. In order to achieve this, Pytorch processes data in batches. A batch is simply a collection of data samples put together. Instead of running an example at a time through the model, and instead of optimising the model with one example at a time, we do this in batches. The DataLoader class converts the Dataset into an iterable object of batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "malware_dataset = MalwareDataset(malware_df=malware_df, preprocess=True, to_torch=True)\n",
    "train_loader = DataLoader(malware_dataset, batch_size=batch_size)\n",
    "batch = next(iter(train_loader))['call_seq']\n",
    "\n",
    "print(f\"Sample shape (before the dataloader) = {malware_dataset[0]['call_seq'].shape}\")\n",
    "print(f\"Batch shape (after the dataloader) = {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Understanding Pytorch layers </h4>\n",
    "\n",
    "Now that we have batched the input, we can explore the fundamental building blocks of deep neural networks, and how they change the data we pass in. A neural net is essentially a complicated function that consists of many, many nested functions. One such function is known as a layer. We build a neural net by passing the input through a layer, and then passing the output from this layer to the next one, and this process goes on until we have a final output. Let's explore some layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the raw logits of the first sample in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1. Linear layer </h4>\n",
    "\n",
    "This is just a linear transformation of the input. That means the input is transformed by this formula:\n",
    "\n",
    "<img src=\"../images/linear.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it up yourself! Here is a link to the documentation: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "linear_layer = ... \n",
    "out = ...\n",
    "\n",
    "print(f\"Input shape = {batch.shape}\")\n",
    "print(f\"Output shape = {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2. ReLU layer </h4>\n",
    "\n",
    "This is the famous ReLU activation function. If the input is positive, the output is positive, else the output is 0.\n",
    "\n",
    "<img src=\"../images/relu.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it up yourself! Here is a link to the documentation: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "relu_layer = ... \n",
    "out = ...\n",
    "\n",
    "print(f\"Input shape = {batch.shape}\")\n",
    "print(f\"Output shape = {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to print the first sample in the batch before passing it into the ReLU layer, and after passing it into the ReLU layer. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2. Sigmoid layer </h4>\n",
    "\n",
    "The sigmoid function is used to squeeze the input into the range [0, 1]. This is convenient when we want to turn the input into probability estimates.\n",
    "\n",
    "<img src=\"../images/sigmoid.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it up yourself! Here is a link to the documentation: https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html\n",
    "sigmoid_layer = ... \n",
    "out = ...\n",
    "\n",
    "print(f\"Input shape = {batch.shape}\")\n",
    "print(f\"Output shape = {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to print the first sample in the batch before passing it into the sigmoid layer, and after passing it into the sigmoid layer. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Building the model </h4>\n",
    "\n",
    "We now know all we need to create a Fully Connected Neural Network (also known as a Multilayer Perceptron). We recommend you try 3-4 hidden layers, where each hidden layer is composed of a Linear and ReLU layer. The Sigmoid layer can be used to compute the final output. Here is a link for inspiration: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html. \n",
    "\n",
    " Let's code it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize the network\n",
    "        # Input: a batched sample, output: the predicted label (0 for no malware, 1 for malware)\n",
    "        #                                  (there should be one prediction per sample in thebatch)\n",
    "\n",
    "        # The network should be composed of Linear, ReLU, and Sigmoid layers\n",
    "        # We suggest looking into the Sequential module (https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html):\n",
    "        self.network = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Your code here\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if the model behaves as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = ...\n",
    "out_features = ...\n",
    "\n",
    "model = MLP(in_features, out_features)\n",
    "out = model(batch)\n",
    "\n",
    "print(f\"Output shape = {out.shape}\")\n",
    "print(f\"The predicted probability of the first being malware = {out[0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and evaluating the model </h2>\n",
    "\n",
    "We now have a model. What's left is to train it, and check how well it performs.\n",
    "\n",
    "Training a neural network consists of the following steps:\n",
    "\n",
    "- Select your hyperparameters. These are parameters that dictate how to train the model, separate from the model parameters that we optimise. The parameters we have included below are the most important ones:\n",
    "\n",
    "    1.  Number of epochs: An epoch is one iteration through the entire training dataset. That means that the model runs through every example from the dataset once, and optimises the parameters based on each example once. One time through the data is usually not enough, and the model needs to see the same examples multiple times to learn all the necessary patterns.\n",
    "\n",
    "    2. Learning rate: This is the gradient descent step size, i.e, how much you wish to change the parameters each time the model learns something new. If you set the value too big, it may not converge, as the parameters can \"jump over\" the minimum. If you set it too small, convergence may happen too slowly. You can look into learning rate schedulers that adapts the learning rate to the loss landscape (but it's probably not necessary for this notebook).\n",
    "\n",
    "    3. Batch size: The size of the batches into which the DataLoader will divide the input (see the DataLoader discussion above). That means the number of examples that the the network runs through in parallel. It also means the number of examples the model uses to calculate the gradient. The loss will be computed for all examples in the batch (usually summing the loss for the individual samples), and the network updates its parameters based on this, using the gradient, one batch at a time. \n",
    "\n",
    "- Iterate through all of the train data once for each epoch, and validate the model once per epoch. That means the outer loop should be iterating through the epochs.\n",
    "\n",
    "- The train loop. The train loop happens inside each epoch. This is where you iterate through all the train data, compute the loss, and run backpropagation. This is what needs to happen:\n",
    "\n",
    "    1. Run the input through the model, and compute the output. This is the forward pass.\n",
    "\n",
    "    2. Calculate the loss, and optimise the parameters with gradient descent and backpropagation.\n",
    "\n",
    "- The validation loop. This happens at the end of an epoch, and is where you evaluate what the model learnt during that epoch. You have set aside a separate dataset to evaluate this. Here, you don't optimise the parameters of the model. Instead, you compute metrics that quantify the performance of the model. For this example, accuracy score (the number of correct predictions), precision, recall, and f1 are good metrics (you should do some Googling if you haven't seen them before). \n",
    "\n",
    "\n",
    "This sounds like a lot, but PyTorch does the heavy lifting. Here is some documentation: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        num_epochs=20,\n",
    "        lr=1e-03,\n",
    "        batch_size=64,\n",
    "):\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=batch_size)\n",
    "\n",
    "    # Your code here ...\n",
    "\n",
    "    optimizer = ...\n",
    "    loss_fn = ...\n",
    "\n",
    "    for epoch in num_epochs:\n",
    "        print(f\"RUNNING EPOCH {epoch}/{num_epochs}\")\n",
    "\n",
    "        # Insert your training and validation code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Done already? Try to improve the model! </h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
