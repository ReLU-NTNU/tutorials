{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take you through implementing your first **Generative Adversarial Net**, or **GAN** for short. We will then train it on the MNIST dataset and try to generate some realistic handdrawn numbers. Lets start by implementing the required libraries. This notebook is inspired by the original GAN paper which you can find [here](https://arxiv.org/abs/1406.2661)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading the data and taking a closer look at it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits, digits and more digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "# we download the data and convert each image into a tensor\n",
    "# the images are gray-scale (one channel), and have values between 0 and 1\n",
    "# representing depending on how bright they are\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = datasets.MNIST(root='./data', \n",
    "                          train=True,\n",
    "                          download=True,\n",
    "                          transform=transform)\n",
    "\n",
    "# We can use the DataLoader class to create a generator object that will yield batches of images and labels.\n",
    "# Depending on your hardware, you may want to adjust the batch size to fit your GPU or CPU memory.\n",
    "BATCH_SIZE = 256\n",
    "dl = torch.utils.data.DataLoader(dataset=train_ds,\n",
    "                shuffle=True,\n",
    "                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple code snippet for showing the images. Run it and see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dl))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(images.to('cpu')[:64], padding=2, normalize=True).cpu(),(1,2,0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, they look like handwritten digits to me. With our data loaded, let's define our two networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tale of two networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin with implementing our discriminator. This network recieves and image as input and outputs a single scalar, the probability of that image being from the real distribution, denoted $p_{data}$. If the image is from our generated distribution, $p_g$, we want our discriminator to output 0 and if they are from $p_{data}$ (or at least that what the discriminator wants, in reality we want our generator to produce results that are so good that the discriminator can't distinguish them, and thus outputs 0.5 regardless of where the image is from). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Define the architecture of the discriminator\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Define the forward pass. Remember to return the output of the last layer\n",
    "        # Hint:     it might be useful to use the view method to flatten the input tensor\n",
    "        #           if you are using fully connected layers.\n",
    "        # Hint 2:   it might be useful to use the sigmoid function to squash the output of the last layer.\n",
    "        #           Alternatively, you can use the BCEWithLogitsLoss loss function, which combines the sigmoid\n",
    "        #           and the binary cross entropy loss in a single class later when defining your loss.\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Define the architecture of the generator\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "            # Define the forward pass. Remember to return the output of the last layer\n",
    "            # Hint:     remember that we want the output of the generator to match\n",
    "            #           the size of the input of the discriminator (the size of the images).\n",
    "            ### START CODE HERE ###\n",
    "    \n",
    "            ### END CODE HERE ###\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at how many trainable parameters we have in our two network. This balance is important, as we want there to be a \"fair battle\" between our networks. Generally, we want our generator network to have more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator(784, 1).to(device)\n",
    "g = Generator(100, 784).to(device)\n",
    "\n",
    "# count the number of trainable parameters\n",
    "print(\"NUMBER OF TRAINABLE PARAMETERS\")\n",
    "d_trainable_params = sum(p.numel() for p in d.parameters() if p.requires_grad)\n",
    "g_trainable_params = sum(p.numel() for p in g.parameters() if p.requires_grad)\n",
    "print(\"Discriminator: \", d_trainable_params)\n",
    "print(\"Generator: \", g_trainable_params)\n",
    "print(\"Fraction of Generator parameters: \", g_trainable_params / (d_trainable_params + g_trainable_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dl, latent_size, epochs=100, device='cpu'):\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "\n",
    "    # Define the loss function and the optimizers for the generator and discriminator\n",
    "    ### START CODE HERE ###\n",
    "    criterion = None\n",
    "    d_optimizer = None\n",
    "    g_optimizer = None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    save_dir = f'models/{time_stamp}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        d_running_loss = 0.0\n",
    "        g_running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(dl):\n",
    "\n",
    "            batch_size = data[0].size(0)\n",
    "\n",
    "            ########################################################\n",
    "            # Train the discriminator\n",
    "            #\n",
    "            # The discriminator is trained to classify images as real or fake.\n",
    "            # We do this by training the discriminator on real images and then on fake images.\n",
    "            # The loss for the discriminator is the sum of the losses for the real and fake images.\n",
    "            ########################################################\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # Train the discriminator on real images\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            real_images, _ = data\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            real_labels = None # create labels for real images\n",
    "            d_real_outputs = None # pass real images through the discriminator\n",
    "            d_real_loss = criterion(d_real_outputs, real_labels)\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Train the discriminator on fake images\n",
    "            ### START CODE HERE ###\n",
    "            z = torch.rand(batch_size, latent_size).to(device) * 2 - 1\n",
    "            with torch.no_grad():\n",
    "                d_fake_images = None # generate fake images\n",
    "\n",
    "            fake_labels = None\n",
    "            d_fake_outputs = None\n",
    "            d_fake_loss = criterion(d_fake_outputs, fake_labels)\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Backpropagate the loss and update the weights\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            d_running_loss += d_loss.item()\n",
    "\n",
    "            ########################################################\n",
    "            # Train the generator\n",
    "            #\n",
    "            # The generator is trained to generate images that are classified as real by the discriminator.\n",
    "            # We do this by generating images and then feeding them to the discriminator and classifying them as real.\n",
    "            # The loss for the generator is the opposite of the loss for the discriminator.\n",
    "            # This is because the generator wants to fool the discriminator into thinking the images are real.\n",
    "            ########################################################\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            z = None\n",
    "            g_fake_images = None\n",
    "\n",
    "            real_labels = None\n",
    "            g_real_outputs = None\n",
    "            g_loss = criterion(g_real_outputs, real_labels)\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Backpropagate the loss and update the weights\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            g_running_loss += g_loss.item()\n",
    "\n",
    "        d_losses.append(d_running_loss / len(dl))\n",
    "        g_losses.append(g_running_loss / len(dl))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            save_path = save_dir + f'/epoch_{epoch}'\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            # Save the models\n",
    "            torch.save(generator.state_dict(), save_path + '/generator.pth')\n",
    "            torch.save(discriminator.state_dict(), save_path + '/discriminator.pth')\n",
    "    save_path = save_dir + '/final'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    # Save the models\n",
    "    torch.save(generator.state_dict(), save_path + '/generator.pth')\n",
    "    torch.save(discriminator.state_dict(), save_path + '/discriminator.pth')\n",
    "    return g_losses, d_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us train the model. Depending on your hardware and batch size, an epoch may take anywhere between a couple of seconds and a couple of minutes 😳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to experiment with the latent size and the number of epochs\n",
    "latent_size = 100\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "g = None # create the generator by making an instance of the Generator class\n",
    "d = None # create the discriminator by making an instance of the Discriminator class\n",
    "# Hint: you can use the 'to' method to move the models to the device, e.g. g.to(device)\n",
    "\n",
    "\n",
    "g_losses, d_losses = train(g, d, dl, latent_size=latent_size, epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_path = 'models/2024-10-01_15-02-08/epoch_180/generator.pth'\n",
    "\n",
    "g = Generator(100, 784).to(device)\n",
    "g.load_state_dict(torch.load(generator_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.eval()\n",
    "\n",
    "z = torch.randn(64, 100).to(device)\n",
    "images = g(z).view(-1, 28, 28).detach().cpu()\n",
    "images = images.unsqueeze(1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(images.to('cpu')[:64], padding=2, normalize=True).cpu(),(1,2,0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
